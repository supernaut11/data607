---
title: "DATA607 - Week 10 Homework"
author: "Mike Dehn"
date: "11/18/2021"
output:
  pdf_document:
    latex_engine : pdflatex
    number_sections: true
bibliography: sources.bib
---

```{r, setup, include=FALSE}
library("caret")
library("curl")
library("randomForest")
library("ROCR")
library("tidyverse")
```

# Introduction

# The Mushroom Data Set

The Mushroom Data Set is a collection of mushroom characteristics originally
described in The Audubon Society Field Guide to North American Mushrooms. 
[@audobon_guide] These records contain hypothetical samples of over 8,000 
individual mushrooms, and include features such as the mushroom shape, color,
and habitat. All features in the data set are categorical. Each mushroom is
labeled as either "edible" or "poisonous".

The data set used in this study is derived from the Machine Learning Repository
maintained by the University of California, Irvine. [@Dua:2019] The data set 
is directly downloaded as part of this paper from an Amazon Web Services (AWS)
S3 bucket. [@mushroom_data]

## Acquiring Data

We download the mushroom data set from the AWS S3 bucket using the `curl`
R package. The data are stored in a Comma-Separated Value (CSV) file with
comma delimiters. Thus, the data are easily ingested using the `read_csv`
function provided by the `tidyverse` package.

```{r}
connection <- curl::curl(
    "https://s3.amazonaws.com/notredame.analytics.data/mushrooms.csv")
raw_data <- read_csv(connection)
```

## Cleaning and Transforming the Data

We process the raw data retrieved from the S3 bucket using a pipeline of data
transformation operations.

First, we downselect our data to only include the original labels (i.e., 
`type`) and four specific features: `odor`, `cap_shape`, `cap_color`, and
`gill_attachment`. All other fields are excluded from our analysis and will
therefore have no impact on the outcome of our classifiers.

Each field in the mushroom data set is categorical, meaning R represents them 
as character strings by default. We transform the columns into factors so that
modeling algorithms can ingest the data set without raising errors.

The label field, `type`, is currently stored as a non-binary factor, which is
problematic for the R implementation of the logistic regression algorithm. We
add a step to the pipeline which converts the `type` field from a factor to an
integer. This transforms "edible" to 1, and "poisonous" to 2. To create a
proper binary field (i.e., 0/1-valued), we subtract 1 from this column and then
transform it back into a factor. Both the linear regression and random forest
models can correctly interpret the `type` label when it is stored as a 
0/1-valued factor.

The final step of our pipeline filters out all samples that contain an `NA` 
value in any of its columns. Although the current data set does not include any
samples with `NA` values, the inclusion of this step shields us from future
updates to the data set that might include an `NA` value.

The R pipeline below performs each of the operations described in this section.

```{r}
# Transform raw data into factorized columns. Also change type column into
# binary field where 0 = edible; 1 = poisonous
mushrooms <- raw_data %>%
    select(type, odor, cap_shape, cap_color, gill_attachment) %>%
    mutate_all(as.factor) %>%
    mutate(type = as.factor(as.numeric(type) - 1)) %>%
    na.exclude
```

Upon execution of this code, the mushroom data set is usable for both linear
regression and random forest classifiers.

## Establishing Training vs. Test Data

Splitting the mushroom data set into separate training and test sets allows us
to build and train models independently of the data used to validate their
performance. Without a train/test split, we have less confidence that our model
generalizes to data it has not seen. For the purposes of this analysis, we 
divide the mushroom data set such that 70 percent of our samples are the
training set, and the remaining 30 percent are the test set.

Prior to splitting the data set, we assign a static random seed via the
`set.seed` function. This makes our results reproducible across multiple
executions by seeding R's random number generator with a known state before
performing operations that require randomness (e.g., randomly sampling the 
whole data set for training data).

```{r}
# Set up training data with a 70/30 split
set.seed(1)
num_train <- floor(nrow(mushrooms) * 0.7)
train_idx <- sample(nrow(mushrooms), num_train)
train_data <- mushrooms[train_idx, ]
test_data <- mushrooms[-train_idx, ]
```

The mushroom data set is now ingested, transformed, and prepared for analysis.
In the proceeding section, we build classifiers that label mushrooms as either
"edible" or "poisonous".

# Edibility Classifier Models

In this analysis, we explore two models that classify the edibility of 
mushrooms using logistic regression and random forest algorithms. These models
are built with basic implementations provided in R packages.

## Logistic Regression Classifier

The logistic regression classifier is a model that uses the logistic function
to represent the probability that an event occurred. By using a maximum 
likelihood estimation approach, we build a binary classifier where the label
is assigned using a cutoff at $p(event) = 0.5$. In other words, a label, $y$ is
assigned such that:

$$
y = 
\begin{cases}
  0 \text{ if } p(event) \leq 0.5 \\
  1 \text{ otherwise}
\end{cases}
$$

Using this rule, we assign a label to a record based on which label is the most
likely in the context of the logistic regression model. In the case of the 
mushroom data set, we represent an edible mushroom as a non-event (valued 0),
and a poisonous mushroom as an event (valued 1).

### Building the Model

The `glm` function provided by R contains an implementation of the logistic
regression algorithm. We provide the mushroom data that we ingested and cleaned
earlier in this report to the `glm` function, providing it only with our
training data set. The logistic regression classifier is configured to predict
the `type` label for the mushroom, which was converted to a binary value in our
previous transformations. Ultimately, the model provides the probability that
a mushroom is poisonous.

The code snippet below trains our logistic regression model for the mushroom
data set.

```{r, include=FALSE}
Rprof()
```
```{r}
# Build logistic regression model and collect profiling info
lr_model <- glm(type ~ ., data = train_data, family = "binomial")
```
```{r, include=FALSE}
Rprof(NULL)
lr_train_time <- summaryRprof()$by.total$total.time[1]
```

The variable `lr_model` now contains our logistic regression model which we use
to classify mushrooms.

### Making Predictions

The `lr_model` logistic regression model we built is now able to perform 
classification of mushrooms on our test data set. To exercise the model, we 
use the `predict` function provided by R. Since our logistic regression model
is designed to provide $p(poisonous)$, we output a label of "0" (i.e., edible)
if $p(poisonous) < 0.5$, otherwise, we output a label of "1" (i.e., poisonous).

```{r}
# Make predictions with logisitic regression model
lr_pred <- predict(lr_model, test_data, type = "response")
lr_pred <- ifelse(lr_pred < 0.5, "0", "1")
```

The confusion matrix below represents the results of our classification against
the test data set.

```{r}
confusionMatrix(table(lr_pred, mushrooms$type[-train_idx]), positive = "1")
```

The ROC curve below provides a graphical representation of the classifier's
performance.

```{r}
lr_pred_roc <- prediction(as.numeric(lr_pred),
                          as.numeric(mushrooms$type[-train_idx]))
roc <- performance(lr_pred_roc, "tpr", "fpr")
plot(roc, colorize = FALSE, lwd = 2, col = "blue", main = "ROC curve")
lines(c(0:100) / 100, c(0:100) / 100, lty = 2)
```

## Random Forest

### Building the Model
```{r}
# Build random forest model and collect profiling info
Rprof()
rf_model <- randomForest(type ~ ., data = train_data)
Rprof(NULL)
rf_train_time <- summaryRprof()$by.total$total.time[1]
```

### Making Predictions
```{r}
# Make predictions with random forest model
rf_pred <- predict(rf_model, test_data, type = "class")

confusionMatrix(table(rf_pred, mushrooms$type[-train_idx]), positive = "1")
```

```{r}
rf_pred_roc <- predict(rf_model, newdata = test_data, type = "prob")
rf_pred_roc <- prediction(rf_pred_roc[, 2],
                          mushrooms$type[-train_idx])
roc <- performance(rf_pred_roc, "tpr", "fpr")
plot(roc, colorize = FALSE, lwd = 2, col = "blue", main = "ROC curve")
lines(c(0:100) / 100, c(0:100) / 100, lty = 2)
```

# Comparative Analysis

## Runtime
```{r}
print(paste("Linear regression training time =", lr_train_time))
print(paste("Random forest training time =", rf_train_time))
```

## Classifier Performance

# Conclusion
