---
title: "DATA607 - Week 10 Homework"
author: "Mike Dehn"
date: "11/18/2021"
output:
  pdf_document:
    latex_engine : pdflatex
    number_sections: true
bibliography: sources.bib
---

```{r, setup, include=FALSE}
library("caret")
library("curl")
library("randomForest")
library("tidyverse")
```

# Introduction

# The Mushroom Data Set

The Mushroom Data Set is a collection of mushroom characteristics originally
described in The Audubon Society Field Guide to North American Mushrooms. 
[@audobon_guide] These records contain hypothetical samples of over 8,000 
individual mushrooms, and include features such as the mushroom shape, color,
and habitat. All features in the data set are categorical. Each mushroom is
labeled as either "edible" or "poisonous".

The data set used in this study is derived from the Machine Learning Repository
maintained by the University of California, Irvine. [@Dua:2019] The data set 
is directly downloaded as part of this paper from an Amazon Web Services (AWS)
S3 bucket. [@mushroom_data]

## Acquiring Data

We download the mushroom data set from the AWS S3 bucket using the `curl`
R package. The data are stored in a Comma-Separated Value (CSV) file with
comma delimiters. Thus, the data are easily ingested using the `read_csv`
function provided by the `tidyverse` package.

```{r}
connection <- curl::curl(
    "https://s3.amazonaws.com/notredame.analytics.data/mushrooms.csv")
raw_data <- read_csv(connection)
```

## Cleaning and Transforming the Data

We process the raw data retrieved from the S3 bucket using a pipeline of data
transformation operations.

First, we downselect our data to only include the original labels (i.e., 
`type`) and four specific features: `odor`, `cap_shape`, `cap_color`, and
`gill_attachment`. All other fields are excluded from our analysis and will
therefore have no impact on the outcome of our classifiers.

Each field in the mushroom data set is categorical, meaning R represents them 
as character strings by default. We transform the columns into factors so that
modeling algorithms can ingest the data set without raising errors.

The label field, `type`, is currently stored as a non-binary factor, which is
problematic for the R implementation of the logistic regression algorithm. We
add a step to the pipeline which converts the `type` field from a factor to an
integer. This transforms "edible" to 1, and "poisonous" to 2. To create a
proper binary field (i.e., 0/1-valued), we subtract 1 from this column and then
transform it back into a factor. Both the linear regression and random forest
models can correctly interpret the `type` label when it is stored as a 
0/1-valued factor.

The final step of our pipeline filters out all samples that contain an `NA` 
value in any of its columns. Although the current data set does not include any
samples with `NA` values, the inclusion of this step shields us from future
updates to the data set that might include an `NA` value.

The R pipeline below performs each of the operations described in this section.

```{r}
# Transform raw data into factorized columns. Also change type column into
# binary field where 0 = edible; 1 = poisonous
mushrooms <- raw_data %>%
    select(type, odor, cap_shape, cap_color, gill_attachment) %>%
    mutate_all(as.factor) %>%
    mutate(type = as.factor(as.integer(type) - 1)) %>%
    na.exclude
```

Upon execution of this code, the mushroom data set is usable for both linear
regression and random forest classifiers.

## Establishing Training vs. Test Data

Splitting the mushroom data set into separate training and test sets allows us
to build and train models independently of the data used to validate their
performance. Without a train/test split, we have less confidence that our model
generalizes to data it has not seen. For the purposes of this analysis, we 
divide the mushroom data set such that 70 percent of our samples are the
training set, and the remaining 30 percent are the test set.

Prior to splitting the data set, we assign a static random seed via the
`set.seed` function. This makes our results reproducible across multiple
executions by seeding R's random number generator with a known state before
performing operations that require randomness (e.g., randomly sampling the 
whole data set for training data).

```{r}
# Set up training data with a 70/30 split
set.seed(1)
num_train <- floor(nrow(mushrooms) * 0.7)
train_idx <- sample(nrow(mushrooms), num_train)
train_data <- mushrooms[train_idx, ]
test_data <- mushrooms[-train_idx, ]
```

The mushroom data set is now ingested, transformed, and prepared for analysis.
In the proceeding section, we build classifiers that label mushrooms as either
"edible" or "poisonous".

# Edibility Classifier Models

## Logistic Regression Classifier

### Building the Model
```{r}
# Build logistic regression model and collect profiling info
Rprof()
lr_model <- glm(type ~ ., data = train_data, family = "binomial")
Rprof(NULL)
lr_train_time <- summaryRprof()$by.total$total.time[1]
```

### Making Predictions
```{r}
# Make predictions with logisitic regression model
lr_pred <- predict(lr_model, test_data, type = "response")
lr_pred <- ifelse(lr_pred < 0.5, "0", "1")

confusionMatrix(table(lr_pred, mushrooms$type[-train_idx]), positive = "1")
```

## Random Forest

### Building the Model
```{r}
# Build random forest model and collect profiling info
Rprof()
rf_model <- randomForest(type ~ ., data = train_data)
Rprof(NULL)
rf_train_time <- summaryRprof()$by.total$total.time[1]
```

### Making Predictions
```{r}
# Make predictions with random forest model
rf_pred <- predict(rf_model, test_data, type = "class")

confusionMatrix(table(rf_pred, mushrooms$type[-train_idx]), positive = "1")
```

# Comparative Analysis

## Runtime
```{r}
print(paste("Linear regression training time =", lr_train_time))
print(paste("Random forest training time =", rf_train_time))
```

## Classifier Performance

# Conclusion
